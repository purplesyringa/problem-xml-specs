# 12. Judging

The tag `<judging>` of `problem.xml` has, perhaps, the most complicated structure, because it stores a lot of information. We will separate this mess into two categories: informative fields and fields that are used to generate the default strategy.

The former category includes:

- The recommended processor to use for testing,
- What testsets are defined,
- Where tests are stored and how they are generated,
- What test groups are defined,
- What limits apply to the user program.

The latter category includes:

- Where the user program is expected to read from and write to,
- Whether the problem is a run-twice problem,
- How PT verdict is interpreted.


## 12.1. Common format

The tag has the following format:

```xml
<judging
    cpu-name="{CPU-NAME}"
    cpu-speed="{CPU-SPEED}"
    input-file="{INPUT-FILE}"
    output-file="{OUTPUT-FILE}"
    [run-count="{RUN-COUNT}"]
    [treat-points-from-checker-as-percent="{TREAT-POINTS-FROM-CHECKER-AS-PERCENT}"]
>
    {TESTSET1}
    {TESTSET2}
    {...}
</judging>
```

`{CPU-NAME}` is the processor model name, such as `Intel(R) Core(TM) i3-8100 CPU @ 3.60GHz` or `Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz`. On Linux, this can be retrieved from `/proc/cpuinfo`. More generally, on x86 processors, it is officially known as "processor brand string" and can be requested using CPUID 0x80000002 till 0x80000004.

`{CPU-SPEED}` is the maximum frequency of the procesor in MHz.

The fields `{INPUT-FILE}`, `{OUTPUT-FILE}`, `{RUN-COUNT}`, and `{TREAT-POINTS-FROM-CHECKER-AS-PERCENT}` are used to generate the default strategy and are described later in [15. Defaults](15-defaults.md).


## 12.2. Testsets

In most cases, all submissions are judged on the exact same tests in the exact same way. But there are exceptions: on Codeforces and some olympiads pretests are separated from system tests, and there may be other reasons to be able to apply different "patterns" of testing. That's what testsets are for.

A testset is a group of tests, independent from other testsets, with its own limits, groups, and so on. A testset is defined as follows:

```xml
<testset name="{NAME}">
    <time-limit>{TIME-LIMIT}</time-limit>
    <memory-limit>{MEMORY-LIMIT}</memory-limit>
    <test-count>{TEST-COUNT}</test-count>
    <input-path-pattern>{TESTS-INPUT-PATTERN}</input-path-pattern>
    <answer-path-pattern>{TESTS-ANSWER-PATTERN}</answer-path-pattern>
    <tests>
        {TEST1}
        {TEST2}
        {...}
    </tests>
    [{GROUPS}]
</testset>
```

`{TIME-LIMIT}` is the CPU time limit in milliseconds. `{MEMORY-LIMIT}` is the memory limit in bytes. Patterns are filesystem path patterns as described in [14. Path patterns](14-path-patterns.md). `{TEST-COUNT}` MUST be equal to the number of nodes in `<tests>`.

Only the names `pretests` and `tests` are allowed. When users write contests, virtual or real, the `pretests` testset should be used for testing, and all submissions are to be retested on the `tests` testset after the contest ends, although judges MAY perform system testing in background without showing the results to the user. The tests of `pretests` MUST be a prefix of tests from `tests`.


## 12.3. Tests

A single test has the following format:

```xml
<test [group="{GROUP}"] [points="{POINTS}"] method="{METHOD}" [cmd="{CMD}"] />
```

Tests are numbered implicitly: the first test has number `1`, and the last test has number `{TEST-COUNT}`.

`{GROUP}`, if present, is the name of the group the test is a part of. `{POINTS}` is the decimal number of points awarded for the test.

`{METHOD}` determines how the test is generated. It can be either of the following:

- `manual`, which means the test is stored in the file denoted by `{TESTS-INPUT-PATTERN}`, or
- `generated`, which means the test is automatically generated by a command specified in `{CMD}`. `{CMD}` is a typical shell command, which means it consists of whitespace-separated arguments which can optionally be wrapped in quotes. The first token of `{CMD}` is the name of the generator program, optionally sans the extension. A matching program MUST be listed in `<executables>` as per [10. Files](10-files.md).

If the method is `manual`, the file at `{TESTS-INPUT-PATTERN}` corresponding to the present test MUST exist. If the method is `generated`, it MAY exist, as preparation systems MAY allow the user to opt out of this.

Similarly, regardless of the method, the file at `{TESTS-ANSWER-PATTERN}` corresponding to the present test MAY exist, as preparation systems MAY allow the user to opt out of this.

In addition, if the method is `generated`, per-test generators are allowed. In this case, the test can be listed as follows:

```xml
<test [group="{GROUP}"] [points="{POINTS}"] method="generated" cmd="{CMD}">
    <executables>
        {EXECUTABLE1}
        {EXECUTABLE2}
        {...}
    </executables>
</test>
```

and `{CMD}` MUST refer to an executable listed among `<executables>`. In this case, the filename specified in `{CMD}` is a base name, not a relative path, so there MUST be exactly one executable among `<executables>` that matches the base name.

Groups, if enabled, are listed as follows:

```xml
<groups>
    {GROUP1}
    {GROUP2}
    {...}
</groups>
```

A group has the following format:

```xml
<group name="{NAME}" feedback-policy="{FEEDBACK-POLICY}" points-policy="{POINTS-POLICY}" />
```

or, if dependencies are present:

```xml
<group name="{NAME}" feedback-policy="{FEEDBACK-POLICY}" points-policy="{POINTS-POLICY}">
    <dependencies>
        <dependency group="{DEPENDENCY1}" />
        <dependency group="{DEPENDENCY2}" />
        {...}
    </dependencies>
</group>
```

`{NAME}` and `{DEPENDENCY}` are all group names. `{FEEDBACK-POLICY}` and `{POINTS-POLICY}` are the policies exactly as specified in [6. Valuation](06-valuation.md).
